{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install TensorTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install -e .. -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import pandas as pd\n",
    "\n",
    "from tensortrade.utils import CryptoDataDownload\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context # Only used if pandas gives a SSLError\n",
    "\n",
    "cdd = CryptoDataDownload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([\n",
    "    cdd.fetch(\"Coinbase\", \"USD\", \"BTC\", \"1h\").add_prefix(\"BTC:\"),\n",
    "    cdd.fetch(\"Coinbase\", \"USD\", \"ETH\", \"1h\").add_prefix(\"ETH:\")\n",
    "], axis=1)\n",
    "data = data.drop([\"ETH:date\"], axis=1)\n",
    "data = data.rename({\"BTC:date\": \"date\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 date  BTC:open  BTC:high  BTC:low  BTC:close  BTC:volume  \\\n0 2017-07-01 11:00:00   2505.56   2513.38  2495.12    2509.17   287000.32   \n1 2017-07-01 12:00:00   2509.17   2512.87  2484.99    2488.43   393142.50   \n2 2017-07-01 13:00:00   2488.43   2488.43  2454.40    2454.43   693254.01   \n3 2017-07-01 14:00:00   2454.43   2473.93  2450.83    2459.35   712864.80   \n4 2017-07-01 15:00:00   2459.35   2475.00  2450.00    2467.83   682105.41   \n\n   ETH:open  ETH:high  ETH:low  ETH:close  ETH:volume  \n0    279.98    279.99    272.1     275.01   679358.87  \n1    275.01    275.01    271.0     274.83   824362.87  \n2    274.83    274.93    265.0     268.79  3010787.99  \n3    268.79    269.90    265.0     265.74  1702536.85  \n4    265.74    272.74    265.0     272.57  1500282.55  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>BTC:open</th>\n      <th>BTC:high</th>\n      <th>BTC:low</th>\n      <th>BTC:close</th>\n      <th>BTC:volume</th>\n      <th>ETH:open</th>\n      <th>ETH:high</th>\n      <th>ETH:low</th>\n      <th>ETH:close</th>\n      <th>ETH:volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-07-01 11:00:00</td>\n      <td>2505.56</td>\n      <td>2513.38</td>\n      <td>2495.12</td>\n      <td>2509.17</td>\n      <td>287000.32</td>\n      <td>279.98</td>\n      <td>279.99</td>\n      <td>272.1</td>\n      <td>275.01</td>\n      <td>679358.87</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-07-01 12:00:00</td>\n      <td>2509.17</td>\n      <td>2512.87</td>\n      <td>2484.99</td>\n      <td>2488.43</td>\n      <td>393142.50</td>\n      <td>275.01</td>\n      <td>275.01</td>\n      <td>271.0</td>\n      <td>274.83</td>\n      <td>824362.87</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-07-01 13:00:00</td>\n      <td>2488.43</td>\n      <td>2488.43</td>\n      <td>2454.40</td>\n      <td>2454.43</td>\n      <td>693254.01</td>\n      <td>274.83</td>\n      <td>274.93</td>\n      <td>265.0</td>\n      <td>268.79</td>\n      <td>3010787.99</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-07-01 14:00:00</td>\n      <td>2454.43</td>\n      <td>2473.93</td>\n      <td>2450.83</td>\n      <td>2459.35</td>\n      <td>712864.80</td>\n      <td>268.79</td>\n      <td>269.90</td>\n      <td>265.0</td>\n      <td>265.74</td>\n      <td>1702536.85</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-07-01 15:00:00</td>\n      <td>2459.35</td>\n      <td>2475.00</td>\n      <td>2450.00</td>\n      <td>2467.83</td>\n      <td>682105.41</td>\n      <td>265.74</td>\n      <td>272.74</td>\n      <td>265.0</td>\n      <td>272.57</td>\n      <td>1500282.55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features with the data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.data import Node, Module, DataFeed, Stream, Select\n",
    "\n",
    "\n",
    "def rsi(price: Node, period: float):\n",
    "    r = price.diff()\n",
    "    upside = r.clamp_min(0).abs()\n",
    "    downside = r.clamp_max(0).abs()\n",
    "    rs = upside.ewm(alpha=1 / period).mean() / downside.ewm(alpha=1 / period).mean()\n",
    "    return 100*(1 - (1 + rs) ** -1)\n",
    "\n",
    "\n",
    "def macd(price: Node, fast: float, slow: float, signal: float) -> Node:\n",
    "    fm = price.ewm(span=fast, adjust=False).mean()\n",
    "    sm = price.ewm(span=slow, adjust=False).mean()\n",
    "    md = fm - sm\n",
    "    signal = md - md.ewm(span=signal, adjust=False).mean()\n",
    "    return signal\n",
    "\n",
    "\n",
    "features = []\n",
    "for c in data.columns[1:]:\n",
    "    s = Stream(list(data[c])).rename(data[c].name)\n",
    "    features += [s]\n",
    "\n",
    "btc_close = Select(\"BTC:close\")(*features)\n",
    "eth_close = Select(\"ETH:close\")(*features)\n",
    "\n",
    "features += [\n",
    "    rsi(btc_close, period=20).rename(\"BTC:rsi\"),\n",
    "    macd(btc_close, fast=10, slow=50, signal=5).rename(\"BTC:macd\"),\n",
    "    rsi(eth_close, period=20).rename(\"ETH:rsi\"),\n",
    "    macd(eth_close, fast=10, slow=50, signal=5).rename(\"ETH:macd\")\n",
    "]\n",
    "        \n",
    "feed = DataFeed(features)\n",
    "feed.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suuser\\PycharmProjects\\tensortrade\\tensortrade\\data\\stream\\node.py:933: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  v = (w[::-1] * x).sum() / w.sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'BTC:open': 2505.56,\n 'BTC:high': 2513.38,\n 'BTC:low': 2495.12,\n 'BTC:close': 2509.17,\n 'BTC:volume': 287000.32,\n 'ETH:open': 279.98,\n 'ETH:high': 279.99,\n 'ETH:low': 272.1,\n 'ETH:close': 275.01,\n 'ETH:volume': 679358.87,\n 'BTC:rsi': nan,\n 'BTC:macd': 0.0,\n 'ETH:rsi': nan,\n 'ETH:macd': 0.0}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Trading Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.exchanges import Exchange\n",
    "from tensortrade.exchanges.services.execution.simulated import execute_order\n",
    "from tensortrade.data import Stream, DataFeed, Module\n",
    "from tensortrade.instruments import USD, BTC, ETH\n",
    "from tensortrade.wallets import Wallet, Portfolio\n",
    "from tensortrade.environments import TradingEnvironment\n",
    "\n",
    "\n",
    "coinbase = Exchange(\"coinbase\", service=execute_order)(\n",
    "    Stream(list(data[\"BTC:close\"])).rename(\"USD-BTC\"),\n",
    "    Stream(list(data[\"ETH:close\"])).rename(\"USD-ETH\")\n",
    ")\n",
    "\n",
    "portfolio = Portfolio(USD, [\n",
    "    Wallet(coinbase, 10000 * USD),\n",
    "    Wallet(coinbase, 0 * BTC),\n",
    "    Wallet(coinbase, 0 * ETH),\n",
    "])\n",
    "\n",
    "env = TradingEnvironment(\n",
    "    feed=feed,\n",
    "    portfolio=portfolio,\n",
    "    use_internal=False,\n",
    "    action_scheme=\"simple\",\n",
    "    reward_scheme=\"risk-adjusted\",\n",
    "    window_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data Feed Observation\n",
    "\n",
    "Even though this observation contains data from the internal data feed, since `use_internal=False` this data will not be provided as input to the observation history. The data that will be added to observation history of the environment will strictly be the nodes that have been included into the data feed that has been provided as a parameter to the trading environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'BTC:open': 2505.56,\n 'BTC:high': 2513.38,\n 'BTC:low': 2495.12,\n 'BTC:close': 2509.17,\n 'BTC:volume': 287000.32,\n 'ETH:open': 279.98,\n 'ETH:high': 279.99,\n 'ETH:low': 272.1,\n 'ETH:close': 275.01,\n 'ETH:volume': 679358.87,\n 'BTC:rsi': 0.0,\n 'BTC:macd': -0.23222985476439617,\n 'ETH:rsi': 0.0,\n 'ETH:macd': -0.0020154953644232945,\n 'coinbase:/USD-BTC': 2509.17,\n 'coinbase:/USD-ETH': 275.01,\n 'coinbase:/USD:/free': 10000.0,\n 'coinbase:/USD:/locked': 0.0,\n 'coinbase:/USD:/total': 10000.0,\n 'coinbase:/BTC:/free': 0.0,\n 'coinbase:/BTC:/locked': 0.0,\n 'coinbase:/BTC:/total': 0.0,\n 'coinbase:/BTC:/worth': 0.0,\n 'coinbase:/ETH:/free': 0.0,\n 'coinbase:/ETH:/locked': 0.0,\n 'coinbase:/ETH:/total': 0.0,\n 'coinbase:/ETH:/worth': 0.0,\n 'net_worth': 10000.0}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.feed.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Train LSTM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====      AGENT ID: b3393885-005e-4716-9ba9-41bc041095bf      ====\n",
      "[10000.00 USD, 0.00000000 BTC, 0.00000000 ETH]\n",
      "====      EPISODE ID (1/200): 14d60026-9423-49e0-873d-bb522b7957dd      ====\n",
      "[10000.00 USD, 0.00000000 BTC, 0.00000000 ETH]\n",
      "10000.0\n",
      "[1849.58 USD, 0.15704677 BTC, 22.89718112 ETH]\n",
      "10201.180474320001\n",
      "[2124.55 USD, 0.29765502 BTC, 18.54184473 ETH]\n",
      "10448.6970810745\n",
      "[5866.98 USD, 0.23065406 BTC, 7.62990017 ETH]\n",
      "10041.489735431\n",
      "[2252.14 USD, 1.04402775 BTC, 0.00000000 ETH]\n",
      "10520.829339722499\n",
      "[0.00 USD, 0.18561419 BTC, 26.83932908 ETH]\n",
      "10351.486199019\n",
      "[0.00 USD, 0.54543583 BTC, 18.06063359 ETH]\n",
      "10545.5790927615\n",
      "[19.91 USD, 0.00247413 BTC, 30.00861381 ETH]\n",
      "10750.131578374101\n",
      "[5880.23 USD, 0.08764593 BTC, 10.87992433 ETH]\n",
      "10515.732367123299\n",
      "[389.30 USD, 0.00393739 BTC, 28.08050214 ETH]\n",
      "10676.748820345001\n",
      "[0.00 USD, 1.21901592 BTC, 1.51385667 ETH]\n",
      "10637.6011715562\n",
      "[0.00 USD, 1.13345477 BTC, 3.08678733 ETH]\n",
      "10502.850024739799\n",
      "[2058.59 USD, 0.48688204 BTC, 9.38414312 ETH]\n",
      "10466.7158884844\n",
      "[5655.82 USD, 0.26760488 BTC, 5.27871825 ETH]\n",
      "10508.985100275\n",
      "[5102.69 USD, 0.46005184 BTC, 2.65017942 ETH]\n",
      "10863.0544215658\n",
      "[4044.30 USD, 0.00449897 BTC, 14.01947967 ETH]\n",
      "10770.9122754663\n",
      "[1718.98 USD, 0.58439711 BTC, 6.22864354 ETH]\n",
      "10519.469092401101\n",
      "[3634.34 USD, 0.02762436 BTC, 13.59575987 ETH]\n",
      "10009.471156772\n",
      "[1561.69 USD, 0.58905826 BTC, 4.41209393 ETH]\n",
      "9074.503745270598\n",
      "[8214.65 USD, 0.04726579 BTC, 2.19893581 ETH]\n",
      "9767.2499394636\n",
      "[482.15 USD, 0.83159022 BTC, 0.00000000 ETH]\n",
      "9682.764403253599\n",
      "[3189.61 USD, 0.43342664 BTC, 3.38195940 ETH]\n",
      "9722.5904325024\n",
      "[779.18 USD, 0.26029550 BTC, 12.38127294 ETH]\n",
      "9560.0064557194\n",
      "[4584.85 USD, 0.39774354 BTC, 0.65994196 ETH]\n",
      "9777.9789023874\n",
      "[0.00 USD, 0.03560974 BTC, 20.48529008 ETH]\n",
      "9526.4059148808\n",
      "[503.67 USD, 0.28330100 BTC, 9.86968228 ETH]\n",
      "9375.482617152\n",
      "[499.07 USD, 0.27963023 BTC, 8.83305916 ETH]\n",
      "9234.855720149299\n",
      "[8485.26 USD, 0.00000000 BTC, 0.18008984 ETH]\n",
      "8566.8569056056\n",
      "[0.00 USD, 0.24857559 BTC, 11.38519252 ETH]\n",
      "9435.7520681732\n",
      "[7407.08 USD, 0.14488169 BTC, 0.00000000 ETH]\n",
      "9836.1649657231\n",
      "[816.91 USD, 0.00458027 BTC, 14.42809686 ETH]\n",
      "10412.646543656001\n",
      "[5217.60 USD, 0.26536928 BTC, 1.21946196 ETH]\n",
      "10548.498225304\n",
      "[3310.06 USD, 0.20500656 BTC, 5.19945106 ETH]\n",
      "10337.339702346999\n",
      "[1032.84 USD, 0.49080809 BTC, 1.39421161 ETH]\n",
      "10767.1969044391\n",
      "[4148.18 USD, 0.21858390 BTC, 3.75641456 ETH]\n",
      "11142.763800845\n",
      "[0.00 USD, 0.00000000 BTC, 15.06560705 ETH]\n",
      "10786.070711377\n",
      "[6912.02 USD, 0.06934135 BTC, 3.29249929 ETH]\n",
      "10973.4304322146\n",
      "[6997.25 USD, 0.16800861 BTC, 0.16894140 ETH]\n",
      "9929.455455937401\n",
      "[8366.30 USD, 0.00000000 BTC, 2.35585475 ETH]\n",
      "10319.303587749999\n",
      "[8393.77 USD, 0.03150245 BTC, 0.38233333 ETH]\n",
      "9116.831028549399\n",
      "[6601.03 USD, 0.06523807 BTC, 2.81442247 ETH]\n",
      "9472.8305445774\n",
      "[2914.36 USD, 0.11582081 BTC, 7.39398072 ETH]\n",
      "9779.83774997\n",
      "[328.10 USD, 0.05440097 BTC, 11.76718283 ETH]\n",
      "9626.112425282101\n",
      "[10371.59 USD, 0.00000000 BTC, 0.00000000 ETH]\n",
      "10371.59\n",
      "[6313.63 USD, 0.01431552 BTC, 5.46791000 ETH]\n",
      "10710.001836544801\n",
      "[7549.53 USD, 0.09782592 BTC, 1.74218118 ETH]\n",
      "10112.9779897836\n",
      "[7008.94 USD, 0.20772778 BTC, 0.00000000 ETH]\n",
      "10108.2384776\n",
      "[4558.34 USD, 0.04752633 BTC, 5.89818023 ETH]\n",
      "9497.0250230002\n",
      "[8865.85 USD, 0.02938805 BTC, 0.00000000 ETH]\n",
      "9245.473662441\n",
      "[9258.80 USD, 0.02578372 BTC, 0.00000000 ETH]\n",
      "9607.086747597199\n",
      "[2321.63 USD, 0.37296615 BTC, 2.77884892 ETH]\n",
      "9582.343633063001\n",
      "[2896.06 USD, 0.49361316 BTC, 0.00000000 ETH]\n",
      "10349.0658692608\n",
      "[1012.76 USD, 0.31255346 BTC, 5.04175144 ETH]\n",
      "10411.199502310199\n",
      "[6744.48 USD, 0.00707116 BTC, 3.75816130 ETH]\n",
      "10586.428436279999\n",
      "[9077.80 USD, 0.14507107 BTC, 0.00000000 ETH]\n",
      "11485.120941265599\n",
      "[4035.19 USD, 0.41011814 BTC, 0.51549685 ETH]\n",
      "11401.419621512801\n",
      "[8423.87 USD, 0.19527555 BTC, 0.43553932 ETH]\n",
      "12041.017822991\n",
      "[7307.98 USD, 0.27131413 BTC, 0.02196561 ETH]\n",
      "11427.0037052637\n",
      "[585.60 USD, 0.28709516 BTC, 5.20492043 ETH]\n",
      "11731.5663394967\n",
      "[2276.59 USD, 0.42332108 BTC, 2.86328656 ETH]\n",
      "11162.852874641601\n",
      "[3172.88 USD, 0.17025073 BTC, 4.76581061 ETH]\n",
      "11257.508698179001\n",
      "[8809.62 USD, 0.18175283 BTC, 0.00232496 ETH]\n",
      "11395.4915744891\n",
      "[4195.64 USD, 0.03455883 BTC, 4.74314948 ETH]\n",
      "11028.3721572\n",
      "[3524.06 USD, 0.52816488 BTC, 0.21743820 ETH]\n",
      "10997.395411292\n",
      "[2537.17 USD, 0.42293520 BTC, 1.92664682 ETH]\n",
      "10479.579394295\n",
      "[1576.63 USD, 0.12704177 BTC, 5.95003109 ETH]\n",
      "8967.2077617311\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from tensortrade.agents import Agent, ReplayMemory\n",
    "\n",
    "A2CTransition = namedtuple('A2CTransition', ['state', 'action', 'reward', 'done', 'value'])\n",
    "\n",
    "\n",
    "class A2C_LSTMAgent_DEV(Agent):\n",
    "\n",
    "    def __init__(self,\n",
    "                 env: 'TradingEnvironment',\n",
    "                 shared_network: tf.keras.Model = None,\n",
    "                 actor_network: tf.keras.Model = None,\n",
    "                 critic_network: tf.keras.Model = None):\n",
    "        self.env = env\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.observation_shape = env.observation_space.shape\n",
    "\n",
    "        self.shared_network = shared_network or self._build_shared_network()\n",
    "        self.actor_network = actor_network or self._build_actor_network()\n",
    "        self.critic_network = critic_network or self._build_critic_network()\n",
    "\n",
    "        self.env.agent_id = self.id\n",
    "\n",
    "    def _build_shared_network(self):\n",
    "        network = tf.keras.Sequential([\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.InputLayer(input_shape=self.observation_shape)),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=64, kernel_size=6, padding=\"same\", activation=\"tanh\")),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling1D(pool_size=2)),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"tanh\")),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling1D(pool_size=2)),\n",
    "            tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()),\n",
    "            tf.keras.layers.LSTM(50, return_sequences=True, stateful=True)\n",
    "\n",
    "        ])\n",
    "        return network\n",
    "\n",
    "    def _build_actor_network(self):\n",
    "        actor_head = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(50, activation='relu'),\n",
    "            tf.keras.layers.Dense(self.n_actions, activation='relu')\n",
    "        ])\n",
    "        #return tf.keras.Sequential([self.shared_network])\n",
    "        return tf.keras.Sequential([self.shared_network, actor_head])\n",
    "\n",
    "    def _build_critic_network(self):\n",
    "        critic_head = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(50, activation='relu'),\n",
    "            tf.keras.layers.Dense(25, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='relu')\n",
    "        ])\n",
    "        #return tf.keras.Sequential([self.shared_network])\n",
    "\n",
    "        return tf.keras.Sequential([self.shared_network, critic_head])\n",
    "\n",
    "    def restore(self, path: str, **kwargs):\n",
    "        actor_filename: str = kwargs.get('actor_filename', None)\n",
    "        critic_filename: str = kwargs.get('critic_filename', None)\n",
    "\n",
    "        if not actor_filename or not critic_filename:\n",
    "            raise ValueError(\n",
    "                'The `restore` method requires a directory `path`, a `critic_filename`, and an `actor_filename`.')\n",
    "\n",
    "        self.actor_network = tf.keras.models.load_model(path + actor_filename)\n",
    "        self.critic_network = tf.keras.models.load_model(path + critic_filename)\n",
    "\n",
    "    def save(self, path: str, **kwargs):\n",
    "        episode: int = kwargs.get('episode', None)\n",
    "\n",
    "        if episode:\n",
    "            suffix = self.id + \"__\" + str(episode).zfill(3) + \".hdf5\"\n",
    "            actor_filename = \"actor_network__\" + suffix\n",
    "            critic_filename = \"critic_network__\" + suffix\n",
    "        else:\n",
    "            actor_filename = \"actor_network__\" + self.id + \".hdf5\"\n",
    "            critic_filename = \"critic_network__\" + self.id + \".hdf5\"\n",
    "\n",
    "        self.actor_network.save(path + actor_filename)\n",
    "        self.critic_network.save(path + critic_filename)\n",
    "\n",
    "    def get_action(self, state: np.ndarray, **kwargs) -> int:\n",
    "        threshold: float = kwargs.get('threshold', 0)\n",
    "\n",
    "        rand = random.random()\n",
    "\n",
    "        if rand < threshold:\n",
    "            return np.random.choice(self.n_actions)\n",
    "        else:\n",
    "            logits = self.actor_network(state[None, None, :], training=False)\n",
    "            return tf.squeeze(tf.squeeze(tf.random.categorical(logits[0], 1), axis=-1), axis=-1)\n",
    "\n",
    "    def _apply_gradient_descent(self,\n",
    "                                memory: ReplayMemory,\n",
    "                                batch_size: int,\n",
    "                                learning_rate: float,\n",
    "                                discount_factor: float,\n",
    "                                entropy_c: float,):\n",
    "        huber_loss = tf.keras.losses.Huber()\n",
    "        wsce_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "        transitions = memory.tail(batch_size)\n",
    "        batch = A2CTransition(*zip(*transitions))\n",
    "\n",
    "        states = tf.convert_to_tensor(batch.state)\n",
    "        actions = tf.convert_to_tensor(batch.action)\n",
    "        rewards = tf.convert_to_tensor(batch.reward, dtype=tf.float32)\n",
    "        dones = tf.convert_to_tensor(batch.done)\n",
    "        values = tf.convert_to_tensor(batch.value)\n",
    "\n",
    "        returns = []\n",
    "        exp_weighted_return = 0\n",
    "\n",
    "        for reward, done in zip(rewards[::-1], dones[::-1]):\n",
    "            exp_weighted_return = reward + discount_factor * exp_weighted_return * (1 - int(done))\n",
    "            returns += [exp_weighted_return]\n",
    "\n",
    "        returns = returns[::-1]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            state_values = self.critic_network(states[None,:])\n",
    "            critic_loss_value = huber_loss(returns, state_values)\n",
    "\n",
    "        gradients = tape.gradient(critic_loss_value, self.critic_network.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, self.critic_network.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            returns = tf.reshape(returns, [batch_size, 1])\n",
    "            advantages = returns - values\n",
    "\n",
    "            actions = tf.cast(actions, tf.int32)\n",
    "            logits = self.actor_network(states[None,:])\n",
    "            policy_loss_value = wsce_loss(actions, logits, sample_weight=advantages)\n",
    "\n",
    "            probs = tf.nn.softmax(logits)\n",
    "            entropy_loss_value = tf.keras.losses.categorical_crossentropy(probs, probs)\n",
    "            policy_total_loss_value = policy_loss_value - entropy_c * entropy_loss_value\n",
    "\n",
    "        gradients = tape.gradient(policy_total_loss_value,\n",
    "                                  self.actor_network.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, self.actor_network.trainable_variables))\n",
    "\n",
    "    def train(self,\n",
    "              n_steps: int = None,\n",
    "              n_episodes: int = None,\n",
    "              save_every: int = None,\n",
    "              save_path: str = None,\n",
    "              callback: callable = None,\n",
    "              **kwargs) -> float:\n",
    "        batch_size: int = kwargs.get('batch_size', 128)\n",
    "        discount_factor: float = kwargs.get('discount_factor', 0.9999)\n",
    "        learning_rate: float = kwargs.get('learning_rate', 0.0001)\n",
    "        eps_start: float = kwargs.get('eps_start', 0.9)\n",
    "        eps_end: float = kwargs.get('eps_end', 0.05)\n",
    "        eps_decay_steps: int = kwargs.get('eps_decay_steps', 200)\n",
    "        entropy_c: int = kwargs.get('entropy_c', 0.0001)\n",
    "        memory_capacity: int = kwargs.get('memory_capacity', 1000)\n",
    "\n",
    "        memory = ReplayMemory(memory_capacity, transition_type=A2CTransition)\n",
    "        episode = 0\n",
    "        steps_done = 0\n",
    "        total_reward = 0\n",
    "        stop_training = False\n",
    "\n",
    "        if n_steps and not n_episodes:\n",
    "            n_episodes = np.iinfo(np.int32).max\n",
    "\n",
    "        print('====      AGENT ID: {}      ===='.format(self.id))\n",
    "\n",
    "        while episode < n_episodes and not stop_training:\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            steps_done = 0\n",
    "            if episode:\n",
    "                self.critic_network.reset_states()\n",
    "                self.actor_network.reset_states()\n",
    "                memory = ReplayMemory(memory_capacity, transition_type=A2CTransition)\n",
    "            print(self.env.portfolio.balances)\n",
    "            print('====      EPISODE ID ({}/{}): {}      ===='.format(episode + 1,\n",
    "                                                                      n_episodes,\n",
    "                                                                      self.env.episode_id))\n",
    "\n",
    "            while not done:\n",
    "                if steps_done % 24 == 0: #each day\n",
    "                    print(self.env.portfolio.balances)\n",
    "                    print(self.env.portfolio.net_worth)\n",
    "                threshold = eps_end + (eps_start - eps_end) * np.exp(-steps_done / eps_decay_steps)\n",
    "                action = self.get_action(state, threshold=threshold)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                value = self.critic_network(state[None, None, :], training=False)\n",
    "                value = tf.squeeze(value, axis=-1)\n",
    "\n",
    "                memory.push(state, action, reward, done, value)\n",
    "\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                steps_done += 1\n",
    "\n",
    "                if self.env.portfolio.net_worth < self.env.portfolio.initial_net_worth * 0.1:\n",
    "                    done = True\n",
    "                    stop_training = True\n",
    "                    continue\n",
    "\n",
    "                if len(memory) < batch_size:\n",
    "                    continue\n",
    "\n",
    "                if steps_done % batch_size == 0:\n",
    "                    self._apply_gradient_descent(memory,\n",
    "                                             batch_size,\n",
    "                                             learning_rate,\n",
    "                                             discount_factor,\n",
    "                                             entropy_c)\n",
    "\n",
    "                if n_steps and steps_done >= n_steps:\n",
    "                    done = True\n",
    "                    #stop_training = True\n",
    "\n",
    "            is_checkpoint = save_every and episode % save_every == 0\n",
    "\n",
    "            if save_path and (is_checkpoint or episode == n_episodes):\n",
    "                self.save(save_path, episode=episode)\n",
    "\n",
    "            episode += 1\n",
    "\n",
    "        mean_reward = total_reward / steps_done\n",
    "\n",
    "        return mean_reward\n",
    "\n",
    "\n",
    "\n",
    "agent = A2C_LSTMAgent_DEV(env)\n",
    "\n",
    "agent.train(n_steps=data.shape[0], batch_size=24*7, n_episodes=200, save_path=\"D:/Users/suuser/Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25272, 11)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}